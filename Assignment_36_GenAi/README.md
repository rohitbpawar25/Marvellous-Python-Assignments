# ü§ñ FLAN-T5 Summarizer & Q&A Assistant  
---

## üìå Project Overview

**Title:** FLAN-T5 Based Text Summarizer and Context-Aware Q&A Assistant  
**Objective:** Build an interactive Python CLI tool that uses **Google‚Äôs FLAN-T5** model to:
- Generate concise **summaries** from long text.
- Answer user questions using only the content from a local **context.txt** file.

---

## üß† Key Features

- Loads **`google/flan-t5-small`** model and tokenizer from HuggingFace `transformers`.
- Generates text completions with `Generate_Test()` using temperature-based sampling.
- Summarizes long text into **4‚Äì6 bullet points** with `Summarize_Test()`.
- Loads local knowledge from `context.txt` using the `Load_Context()` function.
- Answers questions strictly from the loaded context with `Answer_From_Context()`.
- Interactive CLI menu with two options:  
  1. Summarize text  
  2. Question & Answer from local context  
- Graceful handling of missing/empty context file and invalid input.

---

## üß∞ Dependencies

Install required packages with:

```bash
pip install transformers torch
```

> Uses only HuggingFace‚Äôs `transformers` (with PyTorch backend). No datasets are required; only `context.txt` for the Q&A mode.

---

## üìÇ Files & Structure

```
FLAN_T5_Project/
‚îú‚îÄ flan_t5_assistant.py        # main script (contains all functions and CLI)
‚îú‚îÄ context.txt                 # local context file for Q&A (create manually)
‚îî‚îÄ README.md                   # this file
```

> Place `context.txt` in the same directory as the main script before using the Q&A option.

---

## üõ†Ô∏è How the code is organised (functions)

- **Generate_Test(prompt, max_new_tokens=128)** ‚Äî generates text from FLAN-T5 given a prompt.
- **Summarize_Test(text)** ‚Äî summarizes the provided text into 4‚Äì6 bullet points.
- **Load_Context(path="context.txt")** ‚Äî loads and returns text content from a local file.
- **Answer_From_Context(question, context)** ‚Äî answers user questions using only the provided context, returns `"Not found"` if answer is missing.
- **main()** ‚Äî interactive CLI menu to choose between text summarization, context-based Q&A, or exiting the program.

---

## üöÄ Run the project

1. Make sure dependencies are installed.  
2. Place `Assignment26.py` (main script) and `context.txt` (for Q&A mode) in the working directory.  
3. Run the script:

```bash
python3 Assignment26.py
```

The script will:

- Show a menu with options: Summarize text / Q&A from context / Exit.
- Accept multi-line input for summarization and return bullet-point summaries.
- Load content from `context.txt` and answer your questions using only that content.

---

## üìà Example output (sample)

```
------------------------------------------------------------------------------------------
                        FLAN-T5 Summarizer & Q&A Assistant Model                         
                                     Author: Rohit Pawar                                  
                                     Date: 17-09-2025                                     
------------------------------------------------------------------------------------------
1. Summarize the data
2. Questions & Answers over local context.txt
0. Exit
------------------------------------------------------------------------------------------
Choose an option (1/2/0): 1
You have selected Summarisation option...

Paste text to summarize. End with a blank line:
[Your text here...]

Summary generated by Marvellous FLAN model:
‚Ä¢ Point 1
‚Ä¢ Point 2
‚Ä¢ Point 3
‚Ä¢ ...
```

---

## ‚ö†Ô∏è Notes & Tips

- Ensure **`context.txt`** exists before using the Q&A feature; otherwise, the script will show an error.
- Summarization works best on **paragraphs of at least 4‚Äì5 lines**.
- The model used is **`google/flan-t5-small`** which is light-weight and suitable for local experiments.
- Temperature is set to `0.7` for more diverse responses. You can tune `max_new_tokens` and `temperature` for different behavior.
- For reproducibility, the same model weights are loaded each run from HuggingFace Hub.

---

## üßæ Author

**Rohit Pawar**  
**Date:** 17-09-2025  
